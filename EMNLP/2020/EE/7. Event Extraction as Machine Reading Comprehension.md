# Event Extraction as Machine Reading Comprehension
## Abstract
Event extraction (EE) is a crucial information extraction task that aims to extract event information in texts. Previous methods for EE typically model it as a classification task, which are usually prone to the data scarcity problem. In this paper, we propose a new learning paradigm of EE, by explicitly casting it as a machine reading comprehension problem (MRC). Our approach includes an unsupervised question generation process, which can transfer event schema into a set of natural questions, followed by a BERT-based question-answering process to retrieve answers as EE results. This learning paradigm enables us to strengthen the reasoning process of EE, by introducing sophisticated models in MRC, and relieve the data scarcity problem, by introducing the large-scale datasets in MRC. The empirical results show that: i) our approach attains state-of-the-art performance by considerable margins over previous methods. ii) Our model is excelled in the data-scarce scenario, for example, obtaining 49.8% in F1 for event argument extraction with only 1% data, compared with 2.2% of the previous method. iii) Our model also fits with zero-shot scenarios, achieving 37.0% and 16% in F1 on two datasets without using any EE training data.
> 事件提取（EE）是一项至关重要的信息提取任务，旨在提取文本中的事件信息。 EE的先前方法通常将其建模为分类任务，这通常容易出现数据短缺问题。在本文中，我们通过明确将EE转换为机器阅读理解问题（MRC），提出了EE的新学习范式。我们的方法包括一个无监督的问题生成过程，该过程可以将事件模式转换为一组自然问题，然后是基于BERT的问题回答过程，以将答案作为EE结果进行检索。这种学习范例使我们能够通过在MRC中引入复杂的模型来增强EE的推理过程，并通过在MRC中引入大规模数据集来缓解数据短缺问题。实证结果表明：i）我们的方法与以前的方法相比，具有相当高的裕度，可以达到最先进的性能。 ii）我们的模型在数据稀少的情况下表现出色，例如，仅使用1％的数据就可以在F1中获得49.8％的事件参数提取，而以前的方法是2.2％。 iii）我们的模型也适合零击场景，在两个F1数据集上F1分别达到37.0％和16％，而无需使用任何EE训练数据。
## Keywords
- event extraction (EE)
- machine reading comprehension (MRC)
- zero-shot learning
## Key Information
- **Authors:** Jian Liu, Yubo Chen, Kang Liu, Wei Bi, Xiaojiang Liu
- **Organizations**: National Laboratory of Pattern Recognition, Institute of Automation Chinese Academy of Sciences; University of Chinese Academy of Sciences; Beijing Jiaotong University; Tencent AI Lab
- **Datasets**: ACE 2005
- **Codes**: TBA
- **Urls:** [ACL Page](https://www.aclweb.org/anthology/2020.emnlp-main.128/), [Pdf](https://github.com/Clearailhc/KG-NLP-Papers/blob/main/EMNLP/2020/EE/pdf/2020.emnlp-main.128.pdf), Video, [BibTex](https://www.aclweb.org/anthology/2020.emnlp-main.128.bib)
