# Improving Event Detection via Open-domain Trigger Knowledge
## Abstract
Event Detection (ED) is a fundamental task in automatically structuring texts. Due to the small scale of training data, previous methods perform poorly on unseen/sparsely labeled trigger words and are prone to overfitting densely labeled trigger words. To address the issue, we propose a novel Enrichment Knowledge Distillation (EKD) model to leverage external open-domain trigger knowledge to reduce the in-built biases to frequent trigger words in annotations. Experiments on benchmark ACE2005 show that our model outperforms nine strong baselines, is especially effective for unseen/sparsely labeled trigger words. The source code is released on https://github.com/shuaiwa16/ekd.git.
## Keywords
- event detection
- open-domain trigger knowledge
- event coreference resolution
## Key Information
- **Authors:** Prafulla Kumar Choubey; Aaron Lee; Ruihong Huang; Lu Wang
- **Organizations**: Department of Computer Science and Engineering, Texas A&M University; Khoury College of Computer Sciences, Northeastern University
- **Datasets**: [NewsDiscourse corpus](https://github.com/Clearailhc/KG-NLP-Papers/blob/main/ACL/2020/EE/datasets/2020.acl-main.478.Dataset.zip)
- **Codes**: <https://github.com/shuaiwa16/ekd.git>
- **Urls:** [ACL Page](https://www.aclweb.org/anthology/2020.acl-main.478/), [Pdf](https://github.com/Clearailhc/KG-NLP-Papers/blob/main/ACL/2020/EE/pdf/2020.acl-main.478.pdf), [Video](http://slideslive.com/38928770>), [BibTex](https://www.aclweb.org/anthology/2020.acl-main.478.bib)
