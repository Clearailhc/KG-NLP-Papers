# Automatic extraction of personal events from dialogue
## Abstract
In this paper we introduce the problem of extracting events from dialogue. Previous work on event extraction focused on newswire, however we are interested in extracting events from spoken dialogue. To ground this study, we annotated dialogue transcripts from fourteen episodes of the podcast This American Life. This corpus contains 1,038 utterances, made up of 16,962 tokens, of which 3,664 represent events. The agreement for this corpus has a Cohen’s Kappa of 0.83. We have open-sourced this corpus for the NLP community. With this corpus in hand, we trained support vector machines (SVM) to correctly classify these phenomena with 0.68 F1, when using episode-fold cross-validation. This is nearly 100% higher F1 than the baseline classifier. The SVM models achieved performance of over 0.75 F1 on some testing folds. We report the results for SVM classifiers trained with four different types of features (verb classes, part of speech tags, named entities, and semantic role labels), and different machine learning protocols (under-sampling and trigram context). This work is grounded in narratology and computational models of narrative. It is useful for extracting events, plot, and story content from spoken dialogue.
> 在本文中，我们介绍了从对话中提取事件的问题。以前有关事件提取的工作主要集中在新闻专线，但是我们对从口头对话中提取事件感兴趣。为了进行这项研究，我们注释了播客“美国生活”中十四集的对话记录。该语料库包含1,038个语音，由16,962个记号组成，其中3,664个表示事件。此主体的协议的Cohen的Kappa为0.83。我们已经为NLP社区开源了该语料库。有了这个语料库，当使用情节交叉交叉验证时，我们训练了支持向量机（SVM）以0.68 F1正确分类这些现象。这比基线分类器的F1高出近100％。在某些测试褶皱上，SVM模型获得了超过0.75 F1的性能。我们报告了使用四种不同类型的特征（动词类，语音标签的一部分，命名实体和语义角色标签）和不同的机器学习协议（欠采样和Trigram上下文）训练的SVM分类器的结果。这项工作基于叙事的叙事学和计算模型。这对于从语音对话中提取事件，情节和故事内容很有用。
## Keywords
- event detection
- spoken dialogue
## Key Information
- **Authors:** Joshua Eisenberg; Michael Sheriff
- **Organizations**: Artie, Inc; Florida International University, Department of Creative Writing
- **Datasets**: [American Life dialogue](datasets/2020.nuse-1.8.Dataset.zip)
- **Codes**: TBA
- **Urls:** [ACL Page](https://www.aclweb.org/anthology/2020.nuse-1.8/), [Pdf](https://github.com/Clearailhc/KG-NLP-Papers/blob/main/ACL/2020/EE/pdf/2020.nuse-1.8.pdf), [Video](http://slideslive.com/38929747), [BibTex](https://www.aclweb.org/anthology/2020.nuse-1.8.bib)
