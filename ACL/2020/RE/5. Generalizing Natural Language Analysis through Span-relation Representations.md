# Generalizing Natural Language Analysis through Span-relation Representations
## Abstract
Natural language processing covers a wide variety of tasks predicting syntax, semantics, and information content, and usually each type of output is generated with specially designed architectures. In this paper, we provide the simple insight that a great variety of tasks can be represented in a single unified format consisting of labeling spans and relations between spans, thus a single task-independent model can be used across different tasks. We perform extensive experiments to test this insight on 10 disparate tasks spanning dependency parsing (syntax), semantic role labeling (semantics), relation extraction (information content), aspect based sentiment analysis (sentiment), and many others, achieving performance comparable to state-of-the-art specialized models. We further demonstrate benefits of multi-task learning, and also show that the proposed method makes it easy to analyze differences and similarities in how the model handles different tasks. Finally, we convert these datasets into a unified format to build a benchmark, which provides a holistic testbed for evaluating future models for generalized natural language analysis.
> 自然语言处理涵盖了预测语法，语义和信息内容的多种任务，通常每种类型的输出都是通过专门设计的体系结构生成的。在本文中，我们提供了一个简单的见解，即可以以一种由标签跨度和跨度之间的关系组成的统一格式来表示多种任务，因此可以在不同任务之间使用单个独立于任务的模型。我们进行了广泛的实验，以测试10个不同任务的洞察力，这些任务涵盖了依赖关系解析（语法），语义角色标签（语义），关系提取（信息内容），基于方面的情感分析（情感）以及许多其他方面，从而获得了与状态相当的性能最先进的专业模型。我们进一步证明了多任务学习的好处，并且还表明，所提出的方法使分析模型处理不同任务的方式的异同变得容易。最后，我们将这些数据集转换为统一的格式以建立基准，这为评估未来的广义自然语言分析模型提供了一个整体测试平台。
## Keywords
- Natural language processing
- multi-task learning
- generalized natural language analysis
## Key Information
- **Authors:** Zhengbao Jiang; Wei Xu; Jun Araki; Graham Neubig
- **Organizations**: Language Technologies Institute, Carnegie Mellon University; Department of Computer Science and Engineering, Ohio State University
- **Datasets**:  [General Language Analysis Datasets (GLAD) benchmark](https://github.com/neulab/cmu-multinlp)
- **Codes**: <https://github.com/neulab/cmu-multinlp>
- **Urls:** [ACL Page](https://www.aclweb.org/anthology/2020.acl-main.192/), [Pdf](pdf/2020.acl-main.192.pdf), [Video](http://slideslive.com/38928920), [BibTex](https://www.aclweb.org/anthology/2020.acl-main.192.bib)


